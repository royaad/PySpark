{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the PySpark Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the PySpark library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a Spark Session and Reading CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing SparkSession,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a SparkSession instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_instance = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a CSV file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BLS = spark_instance.read.csv(\"../datasets/Loan_Status.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "| Loan_ID|Gender|Married|Dependents|   Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "|LP001002|  Male|     No|         0|    Graduate|           No|           5849|              0.0|      NULL|             360|             1|        Urban|          Y|\n",
      "|LP001003|  Male|    Yes|         1|    Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
      "|LP001005|  Male|    Yes|         0|    Graduate|          Yes|           3000|              0.0|        66|             360|             1|        Urban|          Y|\n",
      "|LP001006|  Male|    Yes|         0|Not Graduate|           No|           2583|           2358.0|       120|             360|             1|        Urban|          Y|\n",
      "|LP001008|  Male|     No|         0|    Graduate|           No|           6000|              0.0|       141|             360|             1|        Urban|          Y|\n",
      "|LP001011|  Male|    Yes|         2|    Graduate|          Yes|           5417|           4196.0|       267|             360|             1|        Urban|          Y|\n",
      "|LP001013|  Male|    Yes|         0|Not Graduate|           No|           2333|           1516.0|        95|             360|             1|        Urban|          Y|\n",
      "|LP001014|  Male|    Yes|        3+|    Graduate|           No|           3036|           2504.0|       158|             360|             0|    Semiurban|          N|\n",
      "|LP001018|  Male|    Yes|         2|    Graduate|           No|           4006|           1526.0|       168|             360|             1|        Urban|          Y|\n",
      "|LP001020|  Male|    Yes|         1|    Graduate|           No|          12841|          10968.0|       349|             360|             1|    Semiurban|          N|\n",
      "|LP001024|  Male|    Yes|         2|    Graduate|           No|           3200|            700.0|        70|             360|             1|        Urban|          Y|\n",
      "|LP001027|  Male|    Yes|         2|    Graduate|         NULL|           2500|           1840.0|       109|             360|             1|        Urban|          Y|\n",
      "|LP001028|  Male|    Yes|         2|    Graduate|           No|           3073|           8106.0|       200|             360|             1|        Urban|          Y|\n",
      "|LP001029|  Male|     No|         0|    Graduate|           No|           1853|           2840.0|       114|             360|             1|        Rural|          N|\n",
      "|LP001030|  Male|    Yes|         2|    Graduate|           No|           1299|           1086.0|        17|             120|             1|        Urban|          Y|\n",
      "+--------+------+-------+----------+------------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_BLS.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      " |-- ApplicantIncome: integer (nullable = true)\n",
      " |-- CoapplicantIncome: double (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- Loan_Amount_Term: integer (nullable = true)\n",
      " |-- Credit_History: integer (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_BLS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking distinct values of columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Gender|\n",
      "+------+\n",
      "|Female|\n",
      "|  Male|\n",
      "|  NULL|\n",
      "+------+\n",
      "\n",
      "+-------+\n",
      "|Married|\n",
      "+-------+\n",
      "|     No|\n",
      "|    Yes|\n",
      "|   NULL|\n",
      "+-------+\n",
      "\n",
      "+----------+\n",
      "|Dependents|\n",
      "+----------+\n",
      "|         0|\n",
      "|         1|\n",
      "|        3+|\n",
      "|         2|\n",
      "|      NULL|\n",
      "+----------+\n",
      "\n",
      "+------------+\n",
      "|   Education|\n",
      "+------------+\n",
      "|Not Graduate|\n",
      "|    Graduate|\n",
      "+------------+\n",
      "\n",
      "+-------------+\n",
      "|Self_Employed|\n",
      "+-------------+\n",
      "|           No|\n",
      "|          Yes|\n",
      "|         NULL|\n",
      "+-------------+\n",
      "\n",
      "+---------------+\n",
      "|ApplicantIncome|\n",
      "+---------------+\n",
      "|           2366|\n",
      "|          11500|\n",
      "|           1025|\n",
      "|           3000|\n",
      "|           3704|\n",
      "+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+\n",
      "|CoapplicantIncome|\n",
      "+-----------------+\n",
      "|           1587.0|\n",
      "|           3440.0|\n",
      "|      16.12000084|\n",
      "|      985.7999878|\n",
      "|           2167.0|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+\n",
      "|LoanAmount|\n",
      "+----------+\n",
      "|       148|\n",
      "|       243|\n",
      "|       137|\n",
      "|        85|\n",
      "|        65|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+\n",
      "|Loan_Amount_Term|\n",
      "+----------------+\n",
      "|             300|\n",
      "|              12|\n",
      "|             360|\n",
      "|             120|\n",
      "|              84|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+\n",
      "|Credit_History|\n",
      "+--------------+\n",
      "|             1|\n",
      "|             0|\n",
      "|          NULL|\n",
      "+--------------+\n",
      "\n",
      "+-------------+\n",
      "|Property_Area|\n",
      "+-------------+\n",
      "|        Urban|\n",
      "|    Semiurban|\n",
      "|        Rural|\n",
      "+-------------+\n",
      "\n",
      "+-----------+\n",
      "|Loan_Status|\n",
      "+-----------+\n",
      "|          Y|\n",
      "|          N|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_BLS.columns[1:]:\n",
    "    df_BLS.select(col).distinct().show(n=5, vertical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply an ML model, we need to transform the categorical columns to numerical.\n",
    "\n",
    "We have the following cases:\n",
    "* Gender: Binary (M/F)\n",
    "* Married: Binary (N/M)\n",
    "* Depedents: Ordinal (0, 1, 2, 3+)\n",
    "* Self_Employed: Binary (N/Y)\n",
    "* Property_Area: Nominal (Urban/Rural/Semi-Urban)\n",
    "* Loan_Status : Binary (N/Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To one hot encode binary columns, we use `StringIndexer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, StringIndexerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting the models, we will drop all nulls for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_df = df_BLS.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the input and output columns for the indexer.\n",
    "\n",
    "We also specify the `stringOrderType` to specify how the strings should be encoded.\n",
    "\n",
    "More info on `stringOrderType` in [this link](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html).\n",
    "\n",
    "For further reading on `StringIndexer`, you can read [link 1](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html) and [link 2](https://www.machinelearningplus.com/pyspark/pyspark-stringindexer/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a StringIndexer instance,\n",
    "\n",
    "The `handleInvalid='keep'` here is of no use, we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "BinCols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Loan_Status']\n",
    "outputCols = ['{}_OHE'.format(c) for c in BinCols]\n",
    "indexer = StringIndexer(inputCols=BinCols, outputCols=outputCols, stringOrderType='alphabetAsc', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Female', 'Male'),\n",
       " ('No', 'Yes'),\n",
       " ('Graduate', 'Not Graduate'),\n",
       " ('No', 'Yes'),\n",
       " ('N', 'Y')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = indexer.fit(ind_df)\n",
    "# Check labelsArray\n",
    "sim.labelsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, since `stringOrderType='alphabetAsc'`, for most cases No/N = 0, while Yes/Y = 1, as N comes before Y in the alphabet.\n",
    "\n",
    "However, for the case of 'Education', Graduate = 0 and Not Graduate = 1, as G comes before N.\n",
    "\n",
    "We can fix since by separating the case of Education from the other cases and taking `stringOrderType='alphabetDesc'` or by changing the labels map (discussed later in this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the dataframe,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "|Gender|Married|   Education|Self_Employed|Loan_Status|Gender_OHE|Married_OHE|Education_OHE|Self_Employed_OHE|Loan_Status_OHE|\n",
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          0.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|          Yes|          Y|       1.0|        1.0|          0.0|              1.0|            1.0|\n",
      "|  Male|    Yes|Not Graduate|           No|          Y|       1.0|        1.0|          1.0|              0.0|            1.0|\n",
      "|  Male|     No|    Graduate|           No|          Y|       1.0|        0.0|          0.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|          Yes|          Y|       1.0|        1.0|          0.0|              1.0|            1.0|\n",
      "|  Male|    Yes|Not Graduate|           No|          Y|       1.0|        1.0|          1.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          0.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|           No|          Y|       1.0|        1.0|          0.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          0.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|           No|          Y|       1.0|        1.0|          0.0|              0.0|            1.0|\n",
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df = sim.transform(ind_df)\n",
    "ind_df.select(BinCols+outputCols).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      " |-- ApplicantIncome: integer (nullable = true)\n",
      " |-- CoapplicantIncome: double (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- Loan_Amount_Term: integer (nullable = true)\n",
      " |-- Credit_History: integer (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Gender_OHE: double (nullable = false)\n",
      " |-- Married_OHE: double (nullable = false)\n",
      " |-- Education_OHE: double (nullable = false)\n",
      " |-- Self_Employed_OHE: double (nullable = false)\n",
      " |-- Loan_Status_OHE: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the labels issue, we can use `from_labelsArray`.\n",
    "\n",
    "We reset the dataframe,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_df = df_BLS.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the wanted `labelArray`.\n",
    "\n",
    "The `labelsArray` should be a list of lists.\n",
    "\n",
    "The following step can be automated using regex; however, for now, I use the easy solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Female', 'Male'],\n",
       " ['No', 'Yes'],\n",
       " ['Not Graduate', 'Graduate'],\n",
       " ['No', 'Yes'],\n",
       " ['N', 'Y']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labelsArray = sim.labelsArray\n",
    "new_labelsArray[2] = (new_labelsArray[2][1], new_labelsArray[2][0])\n",
    "new_labelsArray = [list(x) for x in new_labelsArray]\n",
    "new_labelsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new model from the arrays of labels.\n",
    "\n",
    "`inputCols` and `outputCols` should be redefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Female', 'Male'), ('No', 'Yes'), ('Not Graduate', 'Graduate'), ('No', 'Yes'), ('N', 'Y')]\n",
      "['Gender', 'Married', 'Education', 'Self_Employed', 'Loan_Status']\n",
      "['Gender_OHE', 'Married_OHE', 'Education_OHE', 'Self_Employed_OHE', 'Loan_Status_OHE']\n"
     ]
    }
   ],
   "source": [
    "new_sim = sim.from_arrays_of_labels(new_labelsArray, inputCols=BinCols, outputCols=outputCols)\n",
    "print(new_sim.labelsArray)\n",
    "print(new_sim.getInputCols())\n",
    "print(new_sim.getOutputCols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "|Gender|Married|   Education|Self_Employed|Loan_Status|Gender_OHE|Married_OHE|Education_OHE|Self_Employed_OHE|Loan_Status_OHE|\n",
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          1.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|          Yes|          Y|       1.0|        1.0|          1.0|              1.0|            1.0|\n",
      "|  Male|    Yes|Not Graduate|           No|          Y|       1.0|        1.0|          0.0|              0.0|            1.0|\n",
      "|  Male|     No|    Graduate|           No|          Y|       1.0|        0.0|          1.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|          Yes|          Y|       1.0|        1.0|          1.0|              1.0|            1.0|\n",
      "|  Male|    Yes|Not Graduate|           No|          Y|       1.0|        1.0|          0.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          1.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|           No|          Y|       1.0|        1.0|          1.0|              0.0|            1.0|\n",
      "|  Male|    Yes|    Graduate|           No|          N|       1.0|        1.0|          1.0|              0.0|            0.0|\n",
      "|  Male|    Yes|    Graduate|           No|          Y|       1.0|        1.0|          1.0|              0.0|            1.0|\n",
      "+------+-------+------------+-------------+-----------+----------+-----------+-------------+-----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df = new_sim.transform(ind_df)\n",
    "ind_df.select(BinCols+outputCols).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'Dependents' columns, we have an Ordinal variable.\n",
    "\n",
    "We will thus remove the '+' sign from '3+' and then cast it as a double.\n",
    "\n",
    "To remove the '+' sign, we will use `regex_replace` from sql functions.\n",
    "\n",
    "For more readings on `regex_replace`: [link1](https://www.skytowner.com/explore/removing_substring_in_column_values_of_pyspark_dataframe), [link2](https://community.snowflake.com/s/article/How-REGEXP-REPLACE-and-REPLACE-handle-empty-string), and [link 3](https://medium.com/@uzzaman.ahmed/pyspark-string-functions-a-comprehensive-guide-842c3d68351b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Dependents_ENC' is cast to double by using `cast('double')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|Dependents|Dependents_ENC|\n",
      "+----------+--------------+\n",
      "|         1|           1.0|\n",
      "|         0|           0.0|\n",
      "|         0|           0.0|\n",
      "|         0|           0.0|\n",
      "|         2|           2.0|\n",
      "|         0|           0.0|\n",
      "|        3+|           3.0|\n",
      "|         2|           2.0|\n",
      "|         1|           1.0|\n",
      "|         2|           2.0|\n",
      "+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df = ind_df.withColumn('Dependents_ENC', regexp_replace('Dependents', r\"3\\+\", \"3\").cast('double'))\n",
    "ind_df.select(['Dependents', 'Dependents_ENC']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      " |-- ApplicantIncome: integer (nullable = true)\n",
      " |-- CoapplicantIncome: double (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- Loan_Amount_Term: integer (nullable = true)\n",
      " |-- Credit_History: integer (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Gender_OHE: double (nullable = false)\n",
      " |-- Married_OHE: double (nullable = false)\n",
      " |-- Education_OHE: double (nullable = false)\n",
      " |-- Self_Employed_OHE: double (nullable = false)\n",
      " |-- Loan_Status_OHE: double (nullable = false)\n",
      " |-- Dependents_ENC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df = ind_df.withColumn('Dependents_ENC', ind_df.Dependents_ENC.cast('double'))\n",
    "ind_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do one hot encoding, we should first index the strings, then apply the `OneHotEncoder`.\n",
    "\n",
    "For further reading: [link 1](https://www.machinelearningplus.com/pyspark/pyspark-onehot-encoding/) and [link 2](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by indexing the strings,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|Property_Area|Property_Area_IND|\n",
      "+-------------+-----------------+\n",
      "|        Rural|              2.0|\n",
      "|        Urban|              1.0|\n",
      "|        Urban|              1.0|\n",
      "|        Urban|              1.0|\n",
      "|        Urban|              1.0|\n",
      "|        Urban|              1.0|\n",
      "|    Semiurban|              0.0|\n",
      "|        Urban|              1.0|\n",
      "|    Semiurban|              0.0|\n",
      "|        Urban|              1.0|\n",
      "+-------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sip = StringIndexer(inputCol='Property_Area', outputCol='Property_Area_IND')\n",
    "sim = sip.fit(ind_df)\n",
    "ind_df = sim.transform(ind_df)\n",
    "ind_df.select(['Property_Area', 'Property_Area_IND']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an OHE instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-----------------+\n",
      "|Property_Area|Property_Area_IND|Property_Area_OHE|\n",
      "+-------------+-----------------+-----------------+\n",
      "|        Rural|              2.0|        (2,[],[])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|    Semiurban|              0.0|    (2,[0],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "|    Semiurban|              0.0|    (2,[0],[1.0])|\n",
      "|        Urban|              1.0|    (2,[1],[1.0])|\n",
      "+-------------+-----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(inputCol='Property_Area_IND', outputCol='Property_Area_OHE')\n",
    "model = ohe.fit(ind_df)\n",
    "ind_df = model.transform(ind_df)\n",
    "ind_df.select(['Property_Area', 'Property_Area_IND', 'Property_Area_OHE']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Married: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Self_Employed: string (nullable = true)\n",
      " |-- ApplicantIncome: integer (nullable = true)\n",
      " |-- CoapplicantIncome: double (nullable = true)\n",
      " |-- LoanAmount: integer (nullable = true)\n",
      " |-- Loan_Amount_Term: integer (nullable = true)\n",
      " |-- Credit_History: integer (nullable = true)\n",
      " |-- Property_Area: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Gender_OHE: double (nullable = false)\n",
      " |-- Married_OHE: double (nullable = false)\n",
      " |-- Education_OHE: double (nullable = false)\n",
      " |-- Self_Employed_OHE: double (nullable = false)\n",
      " |-- Loan_Status_OHE: double (nullable = false)\n",
      " |-- Dependents_ENC: double (nullable = true)\n",
      " |-- Property_Area_IND: double (nullable = false)\n",
      " |-- Property_Area_OHE: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ind_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the schema that the OHE creates a vector. This vector is of type sparse.\n",
    "\n",
    "It reads as (dim,[pos],[val]).\n",
    "\n",
    "For example, `(2,[ ],[ ])` is of dimension 2, has no position and value, thus it is the vector [0.0, 0.0].\n",
    "\n",
    "The vector `(2,[1],[1.0])` is of dimension 2, has position 1 and value of 1.0, thus it is the vector [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reorganize ind_df,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+\n",
      "|Gender_OHE|Married_OHE|Dependents_ENC|Education_OHE|Self_Employed_OHE|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area_OHE|Loan_Status_OHE|\n",
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+\n",
      "|       1.0|        1.0|           1.0|          1.0|              0.0|           4583|           1508.0|       128|             360|             1|        (2,[],[])|            0.0|\n",
      "|       1.0|        1.0|           0.0|          1.0|              1.0|           3000|              0.0|        66|             360|             1|    (2,[1],[1.0])|            1.0|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           2583|           2358.0|       120|             360|             1|    (2,[1],[1.0])|            1.0|\n",
      "|       1.0|        0.0|           0.0|          1.0|              0.0|           6000|              0.0|       141|             360|             1|    (2,[1],[1.0])|            1.0|\n",
      "|       1.0|        1.0|           2.0|          1.0|              1.0|           5417|           4196.0|       267|             360|             1|    (2,[1],[1.0])|            1.0|\n",
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colsToKeep = ['Gender_OHE', 'Married_OHE', 'Dependents_ENC', 'Education_OHE',\n",
    "             'Self_Employed_OHE', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "             'Loan_Amount_Term', 'Credit_History', 'Property_Area_OHE', 'Loan_Status_OHE']\n",
    "ind_df = ind_df.select(colsToKeep)\n",
    "ind_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply ML models to my dataframe, I need to put it in a vector format. For that, I import VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we set the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_809e519cd3ce"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputCols = colsToKeep[:-1]\n",
    "outputCol = 'Ind_Vect_Feature'\n",
    "feature_assembler.setParams(inputCols=inputCols, outputCol=outputCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we transform the dataframe,\n",
    "\n",
    "**N.B.** To transform the dataframe, there should be no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+--------------------+\n",
      "|Gender_OHE|Married_OHE|Dependents_ENC|Education_OHE|Self_Employed_OHE|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area_OHE|Loan_Status_OHE|    Ind_Vect_Feature|\n",
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+--------------------+\n",
      "|       1.0|        1.0|           1.0|          1.0|              0.0|           4583|           1508.0|       128|             360|             1|        (2,[],[])|            0.0|[1.0,1.0,1.0,1.0,...|\n",
      "|       1.0|        1.0|           0.0|          1.0|              1.0|           3000|              0.0|        66|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,0.0,1.0,...|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           2583|           2358.0|       120|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,0.0,0.0,...|\n",
      "|       1.0|        0.0|           0.0|          1.0|              0.0|           6000|              0.0|       141|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,0.0,0.0,1.0,...|\n",
      "|       1.0|        1.0|           2.0|          1.0|              1.0|           5417|           4196.0|       267|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           2333|           1516.0|        95|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,0.0,0.0,...|\n",
      "|       1.0|        1.0|           3.0|          1.0|              0.0|           3036|           2504.0|       158|             360|             0|    (2,[0],[1.0])|            0.0|[1.0,1.0,3.0,1.0,...|\n",
      "|       1.0|        1.0|           2.0|          1.0|              0.0|           4006|           1526.0|       168|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       1.0|        1.0|           1.0|          1.0|              0.0|          12841|          10968.0|       349|             360|             1|    (2,[0],[1.0])|            0.0|[1.0,1.0,1.0,1.0,...|\n",
      "|       1.0|        1.0|           2.0|          1.0|              0.0|           3200|            700.0|        70|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       1.0|        1.0|           2.0|          1.0|              0.0|           3073|           8106.0|       200|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       1.0|        0.0|           0.0|          1.0|              0.0|           1853|           2840.0|       114|             360|             1|        (2,[],[])|            0.0|[1.0,0.0,0.0,1.0,...|\n",
      "|       1.0|        1.0|           2.0|          1.0|              0.0|           1299|           1086.0|        17|             120|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       1.0|        0.0|           0.0|          1.0|              0.0|           4950|              0.0|       125|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,0.0,0.0,1.0,...|\n",
      "|       0.0|        0.0|           0.0|          1.0|              0.0|           3510|              0.0|        76|             360|             0|    (2,[1],[1.0])|            0.0|(12,[3,5,7,8,11],...|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           4887|              0.0|       133|             360|             1|        (2,[],[])|            0.0|(12,[0,1,5,7,8,9]...|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           7660|              0.0|       104|             360|             0|    (2,[1],[1.0])|            0.0|(12,[0,1,5,7,8,11...|\n",
      "|       1.0|        1.0|           1.0|          1.0|              0.0|           5955|           5625.0|       315|             360|             1|    (2,[1],[1.0])|            1.0|[1.0,1.0,1.0,1.0,...|\n",
      "|       1.0|        1.0|           0.0|          0.0|              0.0|           2600|           1911.0|       116|             360|             0|    (2,[0],[1.0])|            0.0|[1.0,1.0,0.0,0.0,...|\n",
      "|       1.0|        1.0|           0.0|          1.0|              1.0|           9560|              0.0|       191|             360|             1|    (2,[0],[1.0])|            1.0|[1.0,1.0,0.0,1.0,...|\n",
      "+----------+-----------+--------------+-------------+-----------------+---------------+-----------------+----------+----------------+--------------+-----------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ML = feature_assembler.transform(ind_df)\n",
    "df_ML.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|    Ind_Vect_Feature|Loan_Status_OHE|\n",
      "+--------------------+---------------+\n",
      "|[1.0,1.0,1.0,1.0,...|            0.0|\n",
      "|[1.0,1.0,0.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,0.0,0.0,...|            1.0|\n",
      "|[1.0,0.0,0.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,2.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,0.0,0.0,...|            1.0|\n",
      "|[1.0,1.0,3.0,1.0,...|            0.0|\n",
      "|[1.0,1.0,2.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,1.0,1.0,...|            0.0|\n",
      "|[1.0,1.0,2.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,2.0,1.0,...|            1.0|\n",
      "|[1.0,0.0,0.0,1.0,...|            0.0|\n",
      "|[1.0,1.0,2.0,1.0,...|            1.0|\n",
      "|[1.0,0.0,0.0,1.0,...|            1.0|\n",
      "|(12,[3,5,7,8,11],...|            0.0|\n",
      "|(12,[0,1,5,7,8,9]...|            0.0|\n",
      "|(12,[0,1,5,7,8,11...|            0.0|\n",
      "|[1.0,1.0,1.0,1.0,...|            1.0|\n",
      "|[1.0,1.0,0.0,0.0,...|            0.0|\n",
      "|[1.0,1.0,0.0,1.0,...|            1.0|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ML = df_ML.select(['Ind_Vect_Feature','Loan_Status_OHE'])\n",
    "df_ML.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import `LogisticRegression` from `classification` library,\n",
    "\n",
    "Documentation in this [link](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into train and test samples,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_ML.randomSplit([0.75, 0.25], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "blor = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameters of the instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_3268f8dd183a"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we set the independent features column\n",
    "blor.setFeaturesCol('Ind_Vect_Feature')\n",
    "# we set the labels column\n",
    "blor.setLabelCol('Loan_Status_OHE')\n",
    "# defaul family value is 'auto', other options are 'binomial' and 'multinomial'\n",
    "blor.setFamily('binomial')\n",
    "# MaxInter is 100 by default\n",
    "blor.setMaxIter(1000)\n",
    "# Regularization parameter is 0 by default, 0.1 showed better results\n",
    "blor.setRegParam(0.1)\n",
    "# Standardization is True by default\n",
    "print(blor.getStandardization())\n",
    "# ElasticNetParam is 0 by default. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.\n",
    "blor.setElasticNetParam(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = blor.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the fitted model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,[9],[1.959746866078264])\n",
      "-0.8195179319219494\n"
     ]
    }
   ],
   "source": [
    "print(model.coefficients, model.intercept, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking accuracy on train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172757475083057"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking accuracy on test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7676767676767676"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data).accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional steps to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply Under/Over Sampling in case of imbalance.\n",
    "* Applying imputer to null values (might be better than simply dropping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Loan_Status|count|\n",
      "+-----------+-----+\n",
      "|          Y|  276|\n",
      "|          N|  124|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_BLS.na.drop().select('Loan_Status').groupBy('Loan_Status').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links and Further Readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [7 Techniques to Handle Imbalanced Data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)\n",
    "* [Oversampling and Undersampling with PySpark](https://medium.com/@junwan01/oversampling-and-undersampling-with-pyspark-5dbc25cdf253)\n",
    "* [How do I replace a string value with a NULL in PySpark?](https://stackoverflow.com/questions/36897658/how-do-i-replace-a-string-value-with-a-null-in-pyspark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
